{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQD_zIdyPyaJ"
      },
      "source": [
        "# Importing all the necessary Modules and path variable\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSn-I6qeHK1d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import sklearn as sk\n",
        "import json\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO2SDFqcSBW2",
        "outputId": "4ad2b63d-2c3c-40d6-b45b-c1bd45073447"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Segmentation Models: using `keras` framework.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import segmentation_models as sm\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWiLg0-bSFCD"
      },
      "outputs": [],
      "source": [
        "path = \"Path to the folder which contains the dataset\"\n",
        "b = [\"List of different surgery video sequences\"]\n",
        "b = [path + \"\\\\\" + i for i in b]\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RgGKFSrSe8i"
      },
      "outputs": [],
      "source": [
        "se=[]\n",
        "fr=[]\n",
        "for k in b:\n",
        "  for i in os.listdir(k):\n",
        "    if(i==\".DS_Store\"):\n",
        "      pass\n",
        "    else:\n",
        "      for j in os.listdir(k+\"\\\\\"+i):\n",
        "        if(i==\"frames\"):\n",
        "          fr.append(k+\"\\\\\"+i+\"\\\\\"+j)\n",
        "        elif(i==\"labels\"):\n",
        "          se.append(k+\"\\\\\"+i+\"\\\\\"+j)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCH-TQ0_cBxc"
      },
      "outputs": [],
      "source": [
        "print(se[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrFTE444bcOP"
      },
      "outputs": [],
      "source": [
        "# X is the list of paths to all the frames\n",
        "# y is the list of paths to all the masks\n",
        "X = fr\n",
        "y = se"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qay-ZzRabrIs"
      },
      "outputs": [],
      "source": [
        "print(X[1000],y[1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLxzdIkMcTN-"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT3TxDe7e41w",
        "outputId": "d6544f76-ccfa-42af-cf71-565b15421f6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1024, 1280, 3)\n"
          ]
        }
      ],
      "source": [
        "from matplotlib.pyplot import imread\n",
        "image=imread(X[0])\n",
        "print(image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7hVR-0zfHil"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "Image(X[100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qenchxO8ftmK",
        "outputId": "40fbaf1f-14f4-42d6-d92b-042b8d8a650b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1024, 1280, 3)\n"
          ]
        }
      ],
      "source": [
        "from matplotlib.pyplot import imread\n",
        "image=imread(X[0])\n",
        "print(image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7ovfd7NfuTb"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "Image(y[100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GiT-dX0g2fi",
        "outputId": "a4b85f3d-bbb3-4955-ce25-e328cd791b6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1788"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#splitting the data into train and validation\n",
        "\n",
        "X_train,X_val,y_train,y_val = X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "NUM_IMAGES = len(X_train)\n",
        "NUM_IMAGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDZSwiOycSmJ"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224\n",
        "\n",
        "#Function to preprocess images\n",
        "def preprocess_image(image_path):\n",
        "  ''' Takes image path as input and turns image to a tensor and returns the obtained tensor '''\n",
        "\n",
        "  #Read image file\n",
        "  image=tf.io.read_file(image_path)\n",
        "\n",
        "  #Turn the image into numeric tensor with 3 color channels\n",
        "  image=tf.image.decode_jpeg(image,channels=3)\n",
        "\n",
        "  #Converting color channel values from 0-255 to 0-1\n",
        "  image=tf.image.convert_image_dtype(image,tf.float32)\n",
        "\n",
        "  #Resize the image to 224 224\n",
        "  image=tf.image.resize(image,size=[IMG_SIZE,IMG_SIZE])\n",
        "\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lj8g1Ct5_hgt"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224\n",
        "\n",
        "#Function to preprocess images\n",
        "def preprocess_mask(image_path):\n",
        "  ''' Takes image path as input and turns image to a tensor and returns the obtained tensor '''\n",
        "\n",
        "  #Read image file\n",
        "  image=tf.io.read_file(image_path)\n",
        "\n",
        "  #Turn the image into numeric tensor with 3 color channels\n",
        "  image=tf.image.decode_jpeg(image,channels=3)\n",
        "\n",
        "  #Converting color channel values from 0-255 to 0-1\n",
        "  image=tf.image.convert_image_dtype(image,tf.float32)\n",
        "\n",
        "  #Resize the image to 224 224\n",
        "  image=tf.image.resize(image,size=[IMG_SIZE,IMG_SIZE])\n",
        "\n",
        "  image = tf.cast(image, tf.float32)\n",
        "\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwSqxSZjfQ-x"
      },
      "outputs": [],
      "source": [
        "def get_image_label(image_path,mask):\n",
        "  image=preprocess_image(image_path)\n",
        "  mask=preprocess_mask(mask)\n",
        "  return image,mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPm0ecWkdyaR"
      },
      "outputs": [],
      "source": [
        "#Defining the Batch size\n",
        "BATCH_SIZE = 4\n",
        "#Creating a function to turn the data into batches\n",
        "\n",
        "def create_data_batches(X,y=None,batch_size=BATCH_SIZE,valid_data=False,test_data=False):\n",
        "  '''\n",
        "  This function creates batches of data from images(X) and labels(y).\n",
        "  If the data is training data , the function will return the data after shuffling.\n",
        "  If it is validation data no shuffling will be done.\n",
        "  It does not need to accept labels in case it is test data.\n",
        "\n",
        "  '''\n",
        "  #Case 1 if test data is passed\n",
        "  if test_data:\n",
        "    print(\"Creating test batches...\")\n",
        "    #Create a tensor object using tf.constant and then creating a tensor dataset using Dataset.from_tensor_slices\n",
        "    data=tf.data.Dataset.from_tensor_slices(tf.constant(X))\n",
        "\n",
        "    #Applies the preprocess function across the batches creatied by batch() method using map() method\n",
        "    data_batch=data.map(preprocess_image).batch(batch_size)\n",
        "\n",
        "    #Return the data batch\n",
        "    return data_batch\n",
        "\n",
        "  elif valid_data:\n",
        "    print(\"Creating validation batches...\")\n",
        "    #Create a tensor object using tf.constant and then creating a tensor dataset using Dataset.from_tensor_slices\n",
        "    data=tf.data.Dataset.from_tensor_slices((tf.constant(X),tf.constant(y)))\n",
        "\n",
        "    #Applies the get_image_label function across the batches creatied by batch() method using map() method\n",
        "    data_batch=data.map(get_image_label).batch(batch_size)\n",
        "\n",
        "    #Return the data batch\n",
        "    return data_batch\n",
        "\n",
        "  else:\n",
        "    print(\"Creating training batches...\")\n",
        "    #Create a tensor object using tf.constant and then creating a tensor dataset using Dataset.from_tensor_slices\n",
        "    data=tf.data.Dataset.from_tensor_slices((tf.constant(X),tf.constant(y)))\n",
        "\n",
        "    #Applies the get_image_label function across the batches creatied by batch() method using map() method\n",
        "    data_batch=data.map(get_image_label).batch(batch_size)\n",
        "\n",
        "    #Return the data batch\n",
        "    return data_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgTQAYGodzPe",
        "outputId": "cbcd273c-5bc6-430d-cec6-874f61699c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating training batches...\n",
            "Creating validation batches...\n"
          ]
        }
      ],
      "source": [
        "train_data=create_data_batches(X_train,y_train)\n",
        "val_data=create_data_batches(X_val,y_val,valid_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fX9Qcpsd4lk",
        "outputId": "12cddfb7-9499-4095-bbad-b2ed21148d5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None),\n",
              "  TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None)),\n",
              " (TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None),\n",
              "  TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None)))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.element_spec,val_data.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmiH4t0pd5J_"
      },
      "outputs": [],
      "source": [
        "train_images,train_labels=next(train_data.as_numpy_iterator())\n",
        "val_images,val_labels=next(val_data.as_numpy_iterator())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOmOKcO3iPU3"
      },
      "source": [
        "# Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrVvutD6tO82"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation=tf.keras.layers.PReLU(), input_shape=(224,224,3), padding='same'))\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=tf.keras.layers.PReLU(), padding='same'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout)\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(tf.keras.layers.UpSampling2D(size=(2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(tf.keras.layers.UpSampling2D(size=(2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(tf.keras.layers.Conv2D(filters=3, kernel_size=(3, 3), activation='sigmoid', padding='same'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss=sm.losses.binary_focal_loss,\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
        "                       sm.metrics.IOUScore(threshold=0.5),\n",
        "                       sm.metrics.FScore(threshold=0.5)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bD67wz03iSBu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTppogXSidpP"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,32,kernel_size=3,padding=1,padding_mode=\"reflect\")\n",
        "    self.rel1 = nn.ReLU()\n",
        "    self.conv2 = nn.Conv2d(32,64,kernel_size=3,padding=1,padding_mode=\"reflect\")\n",
        "    self.rel2 = nn.ReLU()\n",
        "    self.mpool = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv3 = nn.Conv2d(64,64,kernel_size=3,padding=1,padding_mode=\"reflect\")\n",
        "    self.rel3 = nn.ReLU()\n",
        "    self.conv4 = nn.Conv2d(64,64,kernel_size=3,padding=1,padding_mode=\"reflect\")\n",
        "    self.rel4 = nn.ReLU()\n",
        "    self.mpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv5 = nn.Conv2d(64,64,kernel_size=3,padding=1,padding_mode=\"reflect\")\n",
        "    self.rel5 = nn.ReLU()\n",
        "    self.conv6 = nn.Conv2d(64,64,kernel_size=3,padding=1,padding_mode=\"reflect\")\n",
        "    self.rel6 = nn.ReLU()\n",
        "    self.upsam = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "    self.conv7 = nn.Conv2d(64,64,kernel_size=3,padding=1,padding_mode=\"reflect\")\n",
        "    self.rel7 = nn.ReLU()\n",
        "    self.conv8 = nn.Conv2d(64,32,kernel_size=3,padding=1,padding_mode=\"reflect\")\n",
        "    self.rel8 = nn.ReLU()\n",
        "    self.upsam2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "    self.conv9 = nn.Conv2d(32,3,kernel_size=3,padding=1,padding_mode=\"reflect\")\n",
        "    self.rel9 = nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.rel1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.rel2(x)\n",
        "    x = self.mpool(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.rel3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.rel4(x)\n",
        "    x = self.mpool2(x)\n",
        "    x = self.conv5(x)\n",
        "    x = self.rel5(x)\n",
        "    x = self.conv6(x)\n",
        "    x = self.rel6(x)\n",
        "    x = self.upsam(x)\n",
        "    x = self.conv7(x)\n",
        "    x = self.rel7(x)\n",
        "    x = self.conv8(x)\n",
        "    x = self.rel8(x)\n",
        "    x = self.upsam2(x)\n",
        "    x = self.conv9(x)\n",
        "    x = self.rel9(x)\n",
        "    return x\n",
        "model = Generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c3_jA53nT6J"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTvtjSRon9S_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity,peak_signal_noise_ratio\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmwlikQtoPoQ"
      },
      "outputs": [],
      "source": [
        "x = Image.open(\"/content/sharp0.jpg\")\n",
        "y = Image.open(\"/content/val_deblurred6.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__QEwO7EoSB1"
      },
      "outputs": [],
      "source": [
        "z_ = np.array(x)\n",
        "z_1 = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmZ5vYNnoeI2",
        "outputId": "54016184-631b-4506-b93f-c230a894d66a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8133068151928011\n"
          ]
        }
      ],
      "source": [
        "print(structural_similarity(z_,z_1,channel_axis=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_ak12jOowS8",
        "outputId": "f88899c3-acd2-42a7-d359-5340c1f193cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27.565735377080514\n"
          ]
        }
      ],
      "source": [
        "print(peak_signal_noise_ratio(z_1,z_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "vANNfsU9nYJ8",
        "outputId": "f4f7fd14-7e04-4a89-aada-f4efd7119218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1        [1, 32, 1024, 1024]             896\n",
            "              ReLU-2        [1, 32, 1024, 1024]               0\n",
            "            Conv2d-3        [1, 64, 1024, 1024]          18,496\n",
            "              ReLU-4        [1, 64, 1024, 1024]               0\n",
            "         MaxPool2d-5          [1, 64, 512, 512]               0\n",
            "            Conv2d-6          [1, 64, 512, 512]          36,928\n",
            "              ReLU-7          [1, 64, 512, 512]               0\n",
            "            Conv2d-8          [1, 64, 512, 512]          36,928\n",
            "              ReLU-9          [1, 64, 512, 512]               0\n",
            "        MaxPool2d-10          [1, 64, 256, 256]               0\n",
            "           Conv2d-11          [1, 64, 256, 256]          36,928\n",
            "             ReLU-12          [1, 64, 256, 256]               0\n",
            "           Conv2d-13          [1, 64, 256, 256]          36,928\n",
            "             ReLU-14          [1, 64, 256, 256]               0\n",
            "UpsamplingNearest2d-15          [1, 64, 512, 512]               0\n",
            "           Conv2d-16          [1, 64, 512, 512]          36,928\n",
            "             ReLU-17          [1, 64, 512, 512]               0\n",
            "           Conv2d-18          [1, 32, 512, 512]          18,464\n",
            "             ReLU-19          [1, 32, 512, 512]               0\n",
            "UpsamplingNearest2d-20        [1, 32, 1024, 1024]               0\n",
            "           Conv2d-21         [1, 3, 1024, 1024]             867\n",
            "             ReLU-22         [1, 3, 1024, 1024]               0\n",
            "================================================================\n",
            "Total params: 223,363\n",
            "Trainable params: 223,363\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 12.00\n",
            "Forward/backward pass size (MB): 3152.00\n",
            "Params size (MB): 0.85\n",
            "Estimated Total Size (MB): 3164.85\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(model, input_size = (3, 1024, 1024), batch_size = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW4zNKYmtsog"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvkM73cPts-3"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import os\n",
        "#Create a function to build a tensorboard callback\n",
        "def create_tensorboard_callback():\n",
        "  logdir=os.path.join(\"./logs\",datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  return tf.keras.callbacks.TensorBoard(logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkuyNUE9tvJk"
      },
      "outputs": [],
      "source": [
        "early_stopping=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=70)\n",
        "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.1,\n",
        "    patience=3,\n",
        "    min_lr=0.00000001\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7b-li6wktwjl"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS=20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igcdkE9XtywP"
      },
      "outputs": [],
      "source": [
        "tensorboard=create_tensorboard_callback()\n",
        "model.fit(x=train_data,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          validation_data=val_data,\n",
        "          validation_freq=1,\n",
        "          callbacks=[tensorboard,early_stopping,lr_callback]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiCwj8IMuDgA"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDldC5b3wxN3",
        "outputId": "1759966a-0646-42e6-cc0b-5e10a2d48e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_333 (Conv2D)         (None, 224, 224, 16)      448       \n",
            "                                                                 \n",
            " conv2d_334 (Conv2D)         (None, 224, 224, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 112, 112, 32)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_335 (Conv2D)         (None, 112, 112, 32)      9248      \n",
            "                                                                 \n",
            " conv2d_336 (Conv2D)         (None, 112, 112, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 56, 56, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_337 (Conv2D)         (None, 56, 56, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_338 (Conv2D)         (None, 56, 56, 32)        9248      \n",
            "                                                                 \n",
            " up_sampling2d_8 (UpSampling  (None, 112, 112, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_339 (Conv2D)         (None, 112, 112, 32)      9248      \n",
            "                                                                 \n",
            " conv2d_340 (Conv2D)         (None, 112, 112, 32)      9248      \n",
            "                                                                 \n",
            " up_sampling2d_9 (UpSampling  (None, 224, 224, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_341 (Conv2D)         (None, 224, 224, 32)      9248      \n",
            "                                                                 \n",
            " conv2d_342 (Conv2D)         (None, 224, 224, 16)      4624      \n",
            "                                                                 \n",
            " conv2d_343 (Conv2D)         (None, 224, 224, 3)       435       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 74,883\n",
            "Trainable params: 74,883\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4S0clArnylG"
      },
      "outputs": [],
      "source": [
        "def save_model(model,suffix=None):\n",
        "  modeldir=os.path.join(\"./models\",datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
        "  model_path=modeldir+'-'+suffix+'.tf'\n",
        "  print(f\"Saving model to {model_path}...\")\n",
        "  model.save(model_path)\n",
        "  return model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgBkd30Le7ah",
        "outputId": "18c8d7ad-39f3-4d18-e57c-1c7ca6326f3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model to ./models\\20240412-233519-Simple_CNN_Segmentation.tf...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 11). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models\\20240412-233519-Simple_CNN_Segmentation.tf\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models\\20240412-233519-Simple_CNN_Segmentation.tf\\assets\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'./models\\\\20240412-233519-Simple_CNN_Segmentation.tf'"
            ]
          },
          "execution_count": 258,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_model(model,suffix=\"Simple_CNN_Segmentation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naKr80NDfIe2"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu-YymhSfJ3Q"
      },
      "outputs": [],
      "source": [
        "#Loading the model\n",
        "m = tf.keras.models.load_model(\"20240413-060137-Simple_CNN_Segmentation_Iter3.tf\",\n",
        "                         custom_objects = {\"binary_crossentropy_plus_jaccard_loss\": loss,\"acc\":acc,\"iou_score\":iou,\"f1-score\":f1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEcKGTBSfYZj"
      },
      "outputs": [],
      "source": [
        "path = \"path to test data\"\n",
        "b = [\"test data sequences\"]\n",
        "b = [path + \"\\\\\" + i +\"\\\\\" + \"frames\" for i in b]\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tdk05l0-folY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "l = []\n",
        "for i in b:\n",
        "  k=[]\n",
        "  for j in os.listdir(i):\n",
        "    k.append(i+\"\\\\\"+j)\n",
        "  l.append(k)\n",
        "print(l[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GqyjQCAftHW"
      },
      "outputs": [],
      "source": [
        "# Getting the seperate video sequences\n",
        "print(len(l))\n",
        "p,q,r,s =l[0],l[1],l[2],l[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JonCA85ufgXg"
      },
      "outputs": [],
      "source": [
        "#converting video sequence into tensor test dataset\n",
        "test_data1=create_data_batches(p,test_data=True)\n",
        "test_data1.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1pDYh6Gfg-0"
      },
      "outputs": [],
      "source": [
        "a = m1.predict(test_data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPz2h62ZfjG9"
      },
      "outputs": [],
      "source": [
        "plt.imshow(a[75])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpchPk2_gCa9"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8777o28f9LT"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir=\"path\\\\logs\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}